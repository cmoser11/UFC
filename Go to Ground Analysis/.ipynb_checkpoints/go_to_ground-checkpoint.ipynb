{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a79b08d-c13d-4024-a088-f27624efb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pandoc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import math\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.proportion import proportions_chisquare\n",
    "from statsmodels.stats.api import het_breuschpagan\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_chisquare\n",
    "from statsmodels.stats.api import het_white\n",
    "\n",
    "from statsmodels.stats.diagnostic import linear_harvey_collier\n",
    "\n",
    "\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.api import het_white\n",
    "\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a775d5b-4a78-4832-b111-fefceeb9cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_path = '/Users/caseymoser/Desktop/UFC Analysis/UFC/Go to Ground Analysis/ufc_fight_stats.csv'\n",
    "\n",
    "results_path = '/Users/caseymoser/Desktop/UFC Analysis/UFC/Go to Ground Analysis/ufc_fight_results.csv'\n",
    "\n",
    "stats_df = pd.read_csv(stats_path)\n",
    "\n",
    "results_df = pd.read_csv(results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a32f3f5-d490-4e1d-a716-7b1b52efb961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tatsuro Taira', 'HyunSung Park', 'Mateusz Rebecki', ...,\n",
       "       'David Levicki', 'Ray Wizard', 'Sean Daugherty'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis is that strikers with more of a grappling base (e.g. bjj blackbelt or wrestling) have a greater finish rate because they are more likely to go to the ground\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399d29e-c06f-4a5a-9b57-4d33c19f038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Tatsuro Taira\n",
      "Processing: HyunSung Park\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from rapidfuzz import fuzz\n",
    "fighter_names =  stats_df['FIGHTER'].unique()\n",
    "def search_wikipedia_page(fighter_name):\n",
    "    search_url = f\"https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={fighter_name}&format=json\"\n",
    "    try:\n",
    "        r = requests.get(search_url, timeout=10)\n",
    "        data = r.json()\n",
    "        pages = data.get('query', {}).get('search', [])\n",
    "        best_match = None\n",
    "        highest_score = 0\n",
    "        for page in pages[:3]:  # check top 3 results\n",
    "            title = page['title']\n",
    "            score = fuzz.token_sort_ratio(fighter_name.lower(), title.lower())\n",
    "            if score > highest_score and score > 70:  # threshold to avoid bad matches\n",
    "                best_match = title\n",
    "                highest_score = score\n",
    "        if best_match:\n",
    "            url = f\"https://en.wikipedia.org/wiki/{best_match.replace(' ', '_')}\"\n",
    "            return url\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching Wikipedia for {fighter_name}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_infobox(soup):\n",
    "    info = {}\n",
    "    infobox = soup.find('table', {'class': 'infobox'})\n",
    "    if not infobox:\n",
    "        return info\n",
    "    for row in infobox.find_all('tr'):\n",
    "        header = row.find('th')\n",
    "        data = row.find('td')\n",
    "        if header and data:\n",
    "            key = header.get_text(strip=True).lower()\n",
    "            value = data.get_text(\" \", strip=True).lower()\n",
    "            info[key] = value\n",
    "    return info\n",
    "\n",
    "def parse_belt_rank(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    belts = ['black belt', 'brown belt', 'purple belt', 'blue belt', 'white belt', 'red belt', 'dan']\n",
    "    found = []\n",
    "    for belt in belts:\n",
    "        if belt in text:\n",
    "            found.append(belt)\n",
    "    dan_match = re.findall(r'(\\d+)(st|nd|rd|th)? dan', text)\n",
    "    if dan_match:\n",
    "        found.extend([f\"{m[0]} dan\" for m in dan_match])\n",
    "    if found:\n",
    "        return \", \".join(found)\n",
    "    return None\n",
    "\n",
    "def check_olympic(text, sport):\n",
    "    if not text:\n",
    "        return 'No'\n",
    "    if 'olympic' in text and sport in text:\n",
    "        return 'Yes'\n",
    "    return 'No'\n",
    "\n",
    "def check_master_of_sport(text):\n",
    "    if not text:\n",
    "        return 'No'\n",
    "    if 'master of sport' in text:\n",
    "        return 'Yes'\n",
    "    return 'No'\n",
    "\n",
    "def get_wrestling_bjj_info(fighter_name, url):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        infobox_data = extract_infobox(soup)\n",
    "        full_text = soup.get_text(separator=' ', strip=True).lower()\n",
    "\n",
    "        bjj_belt_rank = None\n",
    "        judo_belt_rank = None\n",
    "        master_of_sport = 'No'\n",
    "        olympic_wrestler = 'No'\n",
    "        olympic_judo = 'No'\n",
    "        wrestling_background = []\n",
    "        bjj_background = []\n",
    "        other_styles = []\n",
    "\n",
    "        style_text = \"\"\n",
    "        for key in infobox_data:\n",
    "            if 'style' in key or 'martial art' in key or 'rank' in key or 'occupation' in key:\n",
    "                style_text += \" \" + infobox_data[key]\n",
    "\n",
    "        bjj_belt_rank = parse_belt_rank(style_text)\n",
    "        judo_belt_rank = parse_belt_rank(style_text)  # you can refine logic here if needed\n",
    "\n",
    "        master_of_sport = check_master_of_sport(style_text)\n",
    "        olympic_wrestler = check_olympic(style_text, 'wrestling')\n",
    "        olympic_judo = check_olympic(style_text, 'judo')\n",
    "\n",
    "        sentences = re.split(r'(?<=[.!?]) +', full_text)\n",
    "        wrestling_keywords = ['wrestling', 'wrestler', 'ncaa wrestling', 'folkstyle wrestling', 'freestyle wrestling', 'wrestled']\n",
    "        bjj_keywords = ['brazilian jiu-jitsu', 'bjj', 'black belt', 'brown belt', 'purple belt', 'blue belt', 'white belt']\n",
    "        other_styles_keywords = ['boxing', 'muay thai', 'kickboxing', 'karate', 'taekwondo', 'sambo', 'judo']\n",
    "\n",
    "        for sentence in sentences:\n",
    "            lower_sent = sentence.lower()\n",
    "            if any(word in lower_sent for word in wrestling_keywords):\n",
    "                wrestling_background.append(sentence.strip())\n",
    "            if any(word in lower_sent for word in bjj_keywords):\n",
    "                bjj_background.append(sentence.strip())\n",
    "            if any(word in lower_sent for word in other_styles_keywords):\n",
    "                other_styles.append(sentence.strip())\n",
    "\n",
    "        return {\n",
    "            'fighter': fighter_name,\n",
    "            'bjj_belt_rank': bjj_belt_rank,\n",
    "            'judo_belt_rank': judo_belt_rank,\n",
    "            'master_of_sport': master_of_sport,\n",
    "            'olympic_wrestler': olympic_wrestler,\n",
    "            'olympic_judo': olympic_judo,\n",
    "            'wrestling_background': \" | \".join(wrestling_background[:3]),\n",
    "            'bjj_background': \" | \".join(bjj_background[:3]),\n",
    "            'other_styles_summary': \" | \".join(other_styles[:3]),\n",
    "            'wiki_url': url\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {fighter_name} at {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_fighters_background(fighter_names, limit=None):\n",
    "    results = []\n",
    "    missing_fighters = []\n",
    "    count = 0\n",
    "    for name in fighter_names:\n",
    "        print(f\"Processing: {name}\")\n",
    "        wiki_url = search_wikipedia_page(name)\n",
    "        if wiki_url:\n",
    "            info = get_wrestling_bjj_info(name, wiki_url)\n",
    "            if info:\n",
    "                results.append(info)\n",
    "            else:\n",
    "                missing_fighters.append(name)\n",
    "        else:\n",
    "            print(f\"No Wikipedia page found for {name}\")\n",
    "            missing_fighters.append(name)\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(1)  # polite delay\n",
    "\n",
    "        if limit and count >= limit:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df, missing_fighters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: replace this with your actual fighter names list\n",
    "    # from your stats_df['FIGHTER'].unique()\n",
    "\n",
    "    df_background, missing = scrape_fighters_background(fighter_names, limit=None)\n",
    "\n",
    "    print(f\"Scraped data for {len(df_background)} fighters.\")\n",
    "    if missing:\n",
    "        print(f\"Missing Wikipedia pages or scraping failed for {len(missing)} fighters:\")\n",
    "        print(missing)\n",
    "\n",
    "    df_background.to_csv(\"ufc_fighters_bjj_wrestling_info.csv\", index=False)\n",
    "    print(\"Saved to ufc_fighters_bjj_wrestling_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcfa6af-7a27-497d-8f23-e946e82460e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving CSV to: /Users/caseymoser/Desktop/UFC Analysis/UFC/Go to Ground Analysis\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a38792-8ef6-40d9-9862-1932df2edc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
